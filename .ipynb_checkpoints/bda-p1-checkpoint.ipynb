{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f028a71-1655-4603-8c66-f793e5defa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytube is already installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73262/24466175.py:2: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moviepy is already installed.\n",
      "SpeechRecognition is already installed.\n",
      "spacy is already installed.\n",
      "nltk is already installed.\n",
      "nrclex is already installed.\n",
      "textblob is already installed.\n",
      "translate is already installed.\n"
     ]
    }
   ],
   "source": [
    "# Check we have the required packages\n",
    "\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import sys\n",
    "\n",
    "def install_package(package_name):\n",
    "    \"\"\"Install the given package using pip.\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        print(f\"{package_name} installed successfully.\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"Failed to install {package_name}.\")\n",
    "\n",
    "def check_and_install_packages(packages):\n",
    "    \"\"\"Check if packages are installed, and install them if they are not.\"\"\"\n",
    "    for package in packages:\n",
    "        try:\n",
    "            # Check if package is installed by trying to load it\n",
    "            pkg_resources.require(package)\n",
    "            print(f\"{package} is already installed.\")\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            # If not found, install the package\n",
    "            print(f\"{package} not found. Installing...\")\n",
    "            install_package(package)\n",
    "\n",
    "# List of packages to check and install\n",
    "packages_to_check = [\n",
    "    \"pytube\", \"moviepy\", \"SpeechRecognition\", \"spacy\", \"nltk\", \"nrclex\", \"textblob\", \"translate\"\n",
    "]\n",
    "\n",
    "check_and_install_packages(packages_to_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473207bc-8f9a-4e30-9617-4fb86d1f20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/dt_cloud_computing/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from threading import Semaphore, Lock\n",
    "\n",
    "# Third-party imports for concurrent and multiprocessing tasks\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import threading\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "# NLTK and Spacy for natural language processing\n",
    "from nltk import download\n",
    "import spacy\n",
    "\n",
    "# Libraries for video and audio processing\n",
    "from moviepy.editor import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Libraries for web content and translation\n",
    "from pytube import YouTube\n",
    "from translate import Translator\n",
    "\n",
    "# Library for emotion analysis\n",
    "from nrclex import NRCLex\n",
    "\n",
    "# TextBlob for sentiment analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download necessary NLTK data and load Spacy model\n",
    "download('punkt')\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b03f933-4612-4022-916d-2d7d2009be61",
   "metadata": {},
   "source": [
    "# Daniel Timms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c76903f7-7b54-4d2c-a5b5-e043423180fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/dt_cloud_computing/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Let's install our functions from video_processing.py\n",
    "from video_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82aa4010-33a7-45d8-abcd-9144b6f7b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create some directories \n",
    "\n",
    "dirs = [\"video_output\", \"audio_output\", \"text_output\", \n",
    "        \"translated_text\", \"emotion_analysis\", \"sentiment_analysis\"]\n",
    "\n",
    "_ = [Path(d).mkdir(parents=True, exist_ok=True) for d in dirs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02781ee4-4391-428b-b88b-701ab3899c7b",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f15a5c-fdda-48fc-9fd3-08d072a81d24",
   "metadata": {},
   "source": [
    "Manually retrieve 10-15 random video URLs from YouTube.\n",
    "- Save the URLs in a text file called `video_urls.txt` , where each URL should be stored on a separate line.\n",
    "- Consider YouTube videos that are 2-3 minutes in duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224292e3-8bdb-4ea5-90e4-b9e0d7877210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are our URLS we want to analyse\n",
    "urls = [\n",
    "    \"https://www.youtube.com/watch?v=lXJpVz_ig2s\",\n",
    "    \"https://www.youtube.com/watch?v=_Wk9T_G-u4o\",\n",
    "    \"https://www.youtube.com/watch?v=LtScY2guZpo\",\n",
    "    \"https://www.youtube.com/watch?v=CqcEW-jyDmo\",\n",
    "    \"https://www.youtube.com/watch?v=9D-nGIEq6Ms\",\n",
    "    \"https://www.youtube.com/watch?v=xFS7wthXIGg\",\n",
    "    \"https://www.youtube.com/watch?v=UQeyU0YcPKY\",\n",
    "    \"https://www.youtube.com/watch?v=_YPScrckx28\",\n",
    "    \"https://www.youtube.com/watch?v=aeHqYLgZP84\",\n",
    "    \"https://www.youtube.com/watch?v=NYINnu_SWHk\",\n",
    "    \"https://www.youtube.com/watch?v=I1FKT8yHk4k\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4247ac-0bd2-4be7-8bbd-ef25407ccb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs have been saved to video_urls.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = 'video_urls.txt'\n",
    "\n",
    "# Write the URLs to the file\n",
    "with open(file_path, 'w') as file:\n",
    "    for url in urls:\n",
    "        file.write(url + '\\n')\n",
    "\n",
    "print(f\"URLs have been saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aebf029-a2e5-4951-9f98-9bed4d98227e",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586cbeb6-1a5c-4874-adf2-8ee625b0c57a",
   "metadata": {},
   "source": [
    "Develop a Python script to read the URLs.\n",
    " - Assuming you have the text file named video_urls.txt containing the URLs of YouTube videos,\n",
    " - load it in Python and extract the URLs using your preferred data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7749b9-0cb2-49a0-9e7e-656c37776fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs have been read\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = 'video_urls.txt'\n",
    "\n",
    "# Read the URLs from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "# Strip newline characters\n",
    "urls = [url.strip() for url in urls]\n",
    "\n",
    "print(\"URLs have been read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a2df9-0d81-4ac9-bb0c-fa5402148d07",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd140ab-cef2-4cfb-af63-f31ea4744db8",
   "metadata": {},
   "source": [
    "Develop a Python script to download the videos using their URLs.\n",
    "- Test your solution by downloading the files serially.\n",
    "- Use parallel programming such as multiprocessing or threading to handle downloads. Your decision will determine the best strategy.\n",
    "- For testing reasons, ensure the script can download up to 5 videos simultaneously to avoid YouTube blocks.\n",
    "- You are advised to use threads and semaphores to control the downloads.\n",
    "- Compare serial and parallel executions for your video download script.\n",
    "- Discuss the complexity of your video download scripts' time and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c39d76fe-f577-4463-92c5-f08e512bfe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSc Health Data Science.mp4']\n"
     ]
    }
   ],
   "source": [
    "# Where the files will be saved\n",
    "output_path = 'video_output/'\n",
    "\n",
    "# Let's check the function works\n",
    "youtube_downloader(urls[0], output_path)\n",
    "\n",
    "# This should return the name of our first URL/video \n",
    "folder_contents = os.listdir(output_path)\n",
    "print(folder_contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211aff15-e9de-4e0d-85a4-2a5d011046fa",
   "metadata": {},
   "source": [
    "Now we can try to download all our videos and time how long it take to complete, serially. We'll record how long the entire task takes and check we have downloaded the videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c5bbd0-6b29-4219-b66f-dd37da8bfe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading the video serially: 17.216301873999328 second(s)\n",
      "\n",
      "What is Big Data Analytics.mp4\n",
      "Day in the Life Data Scientist.mp4\n",
      "Support Vector Machine (SVM) in 2 minutes.mp4\n",
      "Big Data Analytics for beginners.mp4\n",
      "What is Data Science - A day in the Life of a Data Scientist by IBM 4.mp4\n",
      "MSc Health Data Science.mp4\n",
      "Bill Squadron – How big data analytics continues to change pro sports.mp4\n",
      "Meet Claire Monteleoni Editor in Chief of Environmental Data Science.mp4\n",
      "Job Outlook for Data Science  UMBC.mp4\n",
      "Big Data Analytics For Business  What is Big Data Analytics  Big Data Training  Simplilearn.mp4\n",
      "What is Big Data  Big Data in 2 Minutes  Introduction to Big Data  Big Data Training  Edureka.mp4\n",
      "\n",
      "count of videos downloaded and saved: 11\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Loop through each URL and download the video \n",
    "_ = [youtube_downloader(urls[i], output_path) for i in range(len(urls))]\n",
    "\n",
    "end = time.perf_counter()\n",
    "\n",
    "# Print the time it took\n",
    "print(f'downloading the video serially: {end-start} second(s)')\n",
    "\n",
    "print('')\n",
    "\n",
    "# This should return the names of all 11 videos\n",
    "folder_contents = os.listdir(output_path)\n",
    "_ = [print(item) for item in folder_contents]\n",
    "\n",
    "print('')\n",
    "\n",
    "# check the length\n",
    "print(f'count of videos downloaded and saved: {len(folder_contents)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d95e6e-634f-41a7-af91-9c50cb433fe7",
   "metadata": {},
   "source": [
    "That looks good. We can now attempt to download the files using a parallel method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d289e846-4522-4992-b133-69a4c3891e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-23 18:30:36.449 - Starting download: /watch?v=lXJpVz_ig2s\n",
      "2024-06-23 18:30:36.459 - Starting download: /watch?v=_Wk9T_G-u4o\n",
      "2024-06-23 18:30:36.472 - Starting download: /watch?v=LtScY2guZpo\n",
      "2024-06-23 18:30:36.484 - Starting download: /watch?v=CqcEW-jyDmo\n",
      "2024-06-23 18:30:36.496 - Starting download: /watch?v=9D-nGIEq6Ms\n",
      "2024-06-23 18:30:37.380 - Finished download: /watch?v=_Wk9T_G-u4o\n",
      "2024-06-23 18:30:37.383 - Starting download: /watch?v=xFS7wthXIGg\n",
      "2024-06-23 18:30:37.590 - Finished download: /watch?v=lXJpVz_ig2s\n",
      "2024-06-23 18:30:37.593 - Starting download: /watch?v=UQeyU0YcPKY\n",
      "2024-06-23 18:30:37.650 - Finished download: /watch?v=LtScY2guZpo\n",
      "2024-06-23 18:30:37.653 - Starting download: /watch?v=_YPScrckx28\n",
      "2024-06-23 18:30:37.717 - Finished download: /watch?v=9D-nGIEq6Ms\n",
      "2024-06-23 18:30:37.720 - Starting download: /watch?v=aeHqYLgZP84\n",
      "2024-06-23 18:30:37.729 - Finished download: /watch?v=CqcEW-jyDmo\n",
      "2024-06-23 18:30:37.731 - Starting download: /watch?v=NYINnu_SWHk\n",
      "2024-06-23 18:30:38.591 - Finished download: /watch?v=xFS7wthXIGg\n",
      "2024-06-23 18:30:38.595 - Starting download: /watch?v=I1FKT8yHk4k\n",
      "2024-06-23 18:30:38.772 - Finished download: /watch?v=_YPScrckx28\n",
      "2024-06-23 18:30:38.802 - Finished download: /watch?v=aeHqYLgZP84\n",
      "2024-06-23 18:30:38.811 - Finished download: /watch?v=UQeyU0YcPKY\n",
      "2024-06-23 18:30:38.902 - Finished download: /watch?v=NYINnu_SWHk\n",
      "2024-06-23 18:30:39.664 - Finished download: /watch?v=I1FKT8yHk4k\n",
      ".................................................................\n",
      "*  download videos with multiprocessing: 3.245762 second(s)\n",
      ".................................................................\n",
      "2024-06-23 18:30:39.688 - Starting download: /watch?v=CqcEW-jyDmo\n",
      "2024-06-23 18:30:39.690 - Starting download: /watch?v=lXJpVz_ig2s\n",
      "2024-06-23 18:30:39.691 - Starting download: /watch?v=_Wk9T_G-u4o\n",
      "2024-06-23 18:30:39.691 - Starting download: /watch?v=xFS7wthXIGg\n",
      "2024-06-23 18:30:39.692 - Starting download: /watch?v=LtScY2guZpo\n",
      "2024-06-23 18:30:40.599 - Finished download: /watch?v=_Wk9T_G-u4o\n",
      "2024-06-23 18:30:40.612 - Starting download: /watch?v=9D-nGIEq6Ms\n",
      "2024-06-23 18:30:41.347 - Finished download: /watch?v=LtScY2guZpo\n",
      "2024-06-23 18:30:41.354 - Starting download: /watch?v=UQeyU0YcPKY\n",
      "2024-06-23 18:30:41.684 - Finished download: /watch?v=lXJpVz_ig2s\n",
      "2024-06-23 18:30:41.698 - Starting download: /watch?v=aeHqYLgZP84\n",
      "2024-06-23 18:30:41.965 - Finished download: /watch?v=xFS7wthXIGg\n",
      "2024-06-23 18:30:42.018 - Starting download: /watch?v=_YPScrckx28\n",
      "2024-06-23 18:30:42.082 - Finished download: /watch?v=CqcEW-jyDmo\n",
      "2024-06-23 18:30:42.089 - Starting download: /watch?v=NYINnu_SWHk\n",
      "2024-06-23 18:30:42.577 - Finished download: /watch?v=9D-nGIEq6Ms\n",
      "2024-06-23 18:30:42.592 - Starting download: /watch?v=I1FKT8yHk4k\n",
      "2024-06-23 18:30:43.455 - Finished download: /watch?v=UQeyU0YcPKY\n",
      "2024-06-23 18:30:43.832 - Finished download: /watch?v=_YPScrckx28\n",
      "2024-06-23 18:30:43.834 - Finished download: /watch?v=aeHqYLgZP84\n",
      "2024-06-23 18:30:44.138 - Finished download: /watch?v=NYINnu_SWHk\n",
      "2024-06-23 18:30:44.614 - Finished download: /watch?v=I1FKT8yHk4k\n",
      ".................................................................\n",
      "*  download videos with threading: 4.932104472001811 second(s)\n",
      ".................................................................\n"
     ]
    }
   ],
   "source": [
    "# Setup for concurrency control\n",
    "max_concurrent_downloads = 5\n",
    "manager = Manager()\n",
    "semaphore = manager.Semaphore(max_concurrent_downloads)\n",
    "\n",
    "# Run our two functions and compare times\n",
    "download_videos_multiprocessing(urls, output_path, semaphore)\n",
    "download_videos_threading(urls, output_path, semaphore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be789e4-71db-45a3-bb4f-4bab176eadda",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592a648-fc23-491a-84a6-7425d51fcbb9",
   "metadata": {},
   "source": [
    "Develop a Python script to keep a log for each download.\n",
    "- After downloading each video, create a logger to record which video was downloaded by which process or thread.\n",
    "- Save the log entries to the same file, e.g., download_log.txt .\n",
    "- For this script, you have to use `threads` and a `mutex`.\n",
    "- The entries could be in the following format:\n",
    "\n",
    "```bash\n",
    "\"Timestamp\": 12:23, 21 May 2024, \"URL\":\"http://www.youtube.com/1234\", \"Download\":True\n",
    "\"Timestamp\": 12:25, 21 May 2024, \"URL\":\"http://www.youtube.com/1235\", \"Download\":True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a756f2-be1a-422a-b433-07ef15c3ca52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:30, 23 Jun 2024 - Thread 140695874615040 - Finished download: /watch?v=_Wk9T_G-u4o\n",
      "18:30, 23 Jun 2024 - Thread 140695950116608 - Finished download: /watch?v=CqcEW-jyDmo\n",
      "18:30, 23 Jun 2024 - Thread 140696283477760 - Finished download: /watch?v=xFS7wthXIGg\n",
      "18:30, 23 Jun 2024 - Thread 140695866222336 - Finished download: /watch?v=lXJpVz_ig2s\n",
      "18:30, 23 Jun 2024 - Thread 140695992063744 - Finished download: /watch?v=LtScY2guZpo\n",
      "18:30, 23 Jun 2024 - Thread 140696328836864 - Finished download: /watch?v=9D-nGIEq6Ms\n",
      "18:30, 23 Jun 2024 - Thread 140696241530624 - Finished download: /watch?v=UQeyU0YcPKY\n",
      "18:30, 23 Jun 2024 - Thread 140696008849152 - Finished download: /watch?v=NYINnu_SWHk\n",
      "18:30, 23 Jun 2024 - Thread 140696157636352 - Finished download: /watch?v=aeHqYLgZP84\n",
      "18:30, 23 Jun 2024 - Thread 140696199583488 - Finished download: /watch?v=_YPScrckx28\n",
      "18:30, 23 Jun 2024 - Thread 140696000456448 - Finished download: /watch?v=I1FKT8yHk4k\n",
      ".................................................................\n",
      "*  download videos with threading: 5.2525688399982755 second(s)\n",
      ".................................................................\n"
     ]
    }
   ],
   "source": [
    "manager = Manager()\n",
    "download_semaphore = manager.Semaphore(5)  \n",
    "thread_lock = threading.Lock()\n",
    "\n",
    "# DL videos and make log\n",
    "run_download_video_and_log(urls, output_path, semaphore, thread_lock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21d4d1-316b-4886-b6e7-28bad6ffa09b",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d98ad-6577-4d85-9380-b92e0aed6b0a",
   "metadata": {},
   "source": [
    "Develop Python scripts to perform various video analysis tasks.\n",
    "- After downloading a video, perform the following tasks.\n",
    "- It is preferable to develop a separate script for each functionality.\n",
    "- The five analysis subtasks that you have to develop include the following:\n",
    "    - Extract audio from a video file.\n",
    "    - Transcribe audio to text.\n",
    "    - Perform the sentiment analysis on a video's content, extracting its polarity and sensitivity.\n",
    "    - Translate the text into another language, e.g. Spanish.\n",
    "    - Extract the emotions of a text.\n",
    "- Each output task should store its results in a dedicated folder designated for each video, using the video title. Feel free to organise your folder structure as you prefer.\n",
    "- You can use any library, including `moviepy` for loading video and `speech_recognition` or `textblob` for sentiment analysis.\n",
    "- To implement the analysis subtasks, you must use at least one of the following libraries: `multiprocessing`, `threading`, or `asyncio`.\n",
    "- You must compare serial, multiprocessing, threading, and concurrency for at least one of the subtasks, such as the extracting audio functionality. You do not have to do it for the rest of the subtasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78cb897-ebdf-4461-bcc2-338f9ab85be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio_output/Support Vector Machine (SVM) in 2 minutes.wav\n",
      "MoviePy - Writing audio in audio_output/What is Big Data Analytics.wavMoviePy - Writing audio in audio_output/Big Data Analytics For Business  What is Big Data Analytics  Big Data Training  Simplilearn.wav\n",
      "\n",
      "MoviePy - Writing audio in audio_output/Big Data Analytics for beginners.wav\n",
      "MoviePy - Writing audio in audio_output/What is Big Data  Big Data in 2 Minutes  Introduction to Big Data  Big Data Training  Edureka.wavMoviePy - Writing audio in audio_output/MSc Health Data Science.wavMoviePy - Writing audio in audio_output/Meet Claire Monteleoni Editor in Chief of Environmental Data Science.wav\n",
      "\n",
      "\n",
      "MoviePy - Writing audio in audio_output/What is Data Science - A day in the Life of a Data Scientist by IBM 4.wavMoviePy - Writing audio in audio_output/Bill Squadron – How big data analytics continues to change pro sports.wav\n",
      "\n",
      "MoviePy - Writing audio in audio_output/Day in the Life Data Scientist.wav\n",
      "MoviePy - Writing audio in audio_output/Job Outlook for Data Science  UMBC.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  34%|█████████████████▌                                 | 1177/3426 [00:00<00:00, 2814.90it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted audio to audio_output/Job Outlook for Data Science  UMBC.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted audio to audio_output/Meet Claire Monteleoni Editor in Chief of Environmental Data Science.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  69%|███████████████████████████████████▏               | 2366/3426 [00:00<00:00, 2959.31it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted audio to audio_output/What is Big Data  Big Data in 2 Minutes  Introduction to Big Data  Big Data Training  Edureka.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted audio to audio_output/Support Vector Machine (SVM) in 2 minutes.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted audio to audio_output/What is Big Data Analytics.wav\n",
      "MoviePy - Done.\n",
      "Extracted audio to audio_output/Big Data Analytics for beginners.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.Extracted audio to audio_output/Big Data Analytics For Business  What is Big Data Analytics  Big Data Training  Simplilearn.wav\n",
      "\n",
      "Extracted audio to audio_output/Day in the Life Data Scientist.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted audio to audio_output/Bill Squadron – How big data analytics continues to change pro sports.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted audio to audio_output/MSc Health Data Science.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted audio to audio_output/What is Data Science - A day in the Life of a Data Scientist by IBM 4.wav\n",
      ".................................................................\n",
      "*  Extracting audio from videos took 1.95 second(s)\n",
      ".................................................................\n"
     ]
    }
   ],
   "source": [
    "video_output_path = 'video_output/'\n",
    "audio_output_path = 'audio_output/'\n",
    "\n",
    "# Extract audio from a video file\n",
    "run_extract_audio(video_output_path, audio_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fcb09cf-177f-423d-927f-606401fe8d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed 'audio_output/Job Outlook for Data Science  UMBC.wav' to 'text_output/Job Outlook for Data Science  UMBC.txt'\n",
      "Transcribed 'audio_output/Meet Claire Monteleoni Editor in Chief of Environmental Data Science.wav' to 'text_output/Meet Claire Monteleoni Editor in Chief of Environmental Data Science.txt'\n",
      "Transcribed 'audio_output/Big Data Analytics for beginners.wav' to 'text_output/Big Data Analytics for beginners.txt'\n",
      "Transcribed 'audio_output/What is Big Data  Big Data in 2 Minutes  Introduction to Big Data  Big Data Training  Edureka.wav' to 'text_output/What is Big Data  Big Data in 2 Minutes  Introduction to Big Data  Big Data Training  Edureka.txt'\n",
      "Transcribed 'audio_output/Day in the Life Data Scientist.wav' to 'text_output/Day in the Life Data Scientist.txt'\n",
      "Transcribed 'audio_output/Big Data Analytics For Business  What is Big Data Analytics  Big Data Training  Simplilearn.wav' to 'text_output/Big Data Analytics For Business  What is Big Data Analytics  Big Data Training  Simplilearn.txt'\n",
      "Transcribed 'audio_output/What is Big Data Analytics.wav' to 'text_output/What is Big Data Analytics.txt'\n",
      "Transcribed 'audio_output/Bill Squadron – How big data analytics continues to change pro sports.wav' to 'text_output/Bill Squadron – How big data analytics continues to change pro sports.txt'\n",
      "Transcribed 'audio_output/MSc Health Data Science.wav' to 'text_output/MSc Health Data Science.txt'\n",
      "Transcribed 'audio_output/Support Vector Machine (SVM) in 2 minutes.wav' to 'text_output/Support Vector Machine (SVM) in 2 minutes.txt'\n",
      "Transcribed 'audio_output/What is Data Science - A day in the Life of a Data Scientist by IBM 4.wav' to 'text_output/What is Data Science - A day in the Life of a Data Scientist by IBM 4.txt'\n",
      ".................................................................\n",
      "*  Transcribing text from audio took 106.51 second(s)\n",
      ".................................................................\n"
     ]
    }
   ],
   "source": [
    "audio_output_path = 'audio_output/'\n",
    "text_output_path  = 'text_output/'\n",
    "\n",
    "# Transcribe audio to text\n",
    "run_transcribe_audio(audio_output_path, text_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6879420-7953-4dc6-b386-4dad55641b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................\n",
      "*  Transcribing text from audio took 0.27 second(s)\n",
      ".................................................................\n"
     ]
    }
   ],
   "source": [
    "text_input_path  = 'text_output/'\n",
    "json_output_path = 'sentiment_analysis/'\n",
    "\n",
    "# Perform the sentiment analysis on a video's content, extracting its polarity and sensitivity\n",
    "run_analyze_sentiment(text_input_path, json_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce76e725-b988-41e5-ba4d-200513a8a3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated 'Job Outlook for Data Science  UMBC.txt' to Spanish and saved to 'translated_text/Job Outlook for Data Science  UMBC.txt'\n",
      "Translated 'What is Big Data  Big Data in 2 Minutes  Introduction to Big Data  Big Data Training  Edureka.txt' to Spanish and saved to 'translated_text/What is Big Data  Big Data in 2 Minutes  Introduction to Big Data  Big Data Training  Edureka.txt'\n",
      "Translated 'Big Data Analytics for beginners.txt' to Spanish and saved to 'translated_text/Big Data Analytics for beginners.txt'\n",
      "Translated 'What is Big Data Analytics.txt' to Spanish and saved to 'translated_text/What is Big Data Analytics.txt'\n",
      "Translated 'Big Data Analytics For Business  What is Big Data Analytics  Big Data Training  Simplilearn.txt' to Spanish and saved to 'translated_text/Big Data Analytics For Business  What is Big Data Analytics  Big Data Training  Simplilearn.txt'\n",
      "Translated 'Meet Claire Monteleoni Editor in Chief of Environmental Data Science.txt' to Spanish and saved to 'translated_text/Meet Claire Monteleoni Editor in Chief of Environmental Data Science.txt'\n",
      "Translated 'MSc Health Data Science.txt' to Spanish and saved to 'translated_text/MSc Health Data Science.txt'\n",
      "Translated 'Bill Squadron – How big data analytics continues to change pro sports.txt' to Spanish and saved to 'translated_text/Bill Squadron – How big data analytics continues to change pro sports.txt'\n",
      "Translated 'Day in the Life Data Scientist.txt' to Spanish and saved to 'translated_text/Day in the Life Data Scientist.txt'\n",
      "Translated 'Support Vector Machine (SVM) in 2 minutes.txt' to Spanish and saved to 'translated_text/Support Vector Machine (SVM) in 2 minutes.txt'\n",
      "Translated 'What is Data Science - A day in the Life of a Data Scientist by IBM 4.txt' to Spanish and saved to 'translated_text/What is Data Science - A day in the Life of a Data Scientist by IBM 4.txt'\n",
      ".................................................................\n",
      "*  translating text from english to spanish 3.59 second(s)\n",
      ".................................................................\n"
     ]
    }
   ],
   "source": [
    "input_directory  = 'text_output/'\n",
    "output_directory = 'translated_text/'\n",
    "\n",
    "# Translate the text into another language, e.g. Spanish\n",
    "run_translate_file(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7046534e-64b4-4730-b705-c0dbf59d1323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text_output/What is Big Data  Big Data in 2 Minutes  Introduction to Big Data  Big Data Training  Edureka.txt: Emotions saved to emotion_analysis/What is Big Data  Big Data in 2 Minutes  Introduction to Big Data  Big Data Training  Edureka_emotions.json\n",
      "Processed text_output/Job Outlook for Data Science  UMBC.txt: Emotions saved to emotion_analysis/Job Outlook for Data Science  UMBC_emotions.json\n",
      "Processed text_output/Big Data Analytics For Business  What is Big Data Analytics  Big Data Training  Simplilearn.txt: Emotions saved to emotion_analysis/Big Data Analytics For Business  What is Big Data Analytics  Big Data Training  Simplilearn_emotions.json\n",
      "Processed text_output/What is Big Data Analytics.txt: Emotions saved to emotion_analysis/What is Big Data Analytics_emotions.json\n",
      "Processed text_output/Meet Claire Monteleoni Editor in Chief of Environmental Data Science.txt: Emotions saved to emotion_analysis/Meet Claire Monteleoni Editor in Chief of Environmental Data Science_emotions.json\n",
      "Processed text_output/Support Vector Machine (SVM) in 2 minutes.txt: Emotions saved to emotion_analysis/Support Vector Machine (SVM) in 2 minutes_emotions.json\n",
      "Processed text_output/Big Data Analytics for beginners.txt: Emotions saved to emotion_analysis/Big Data Analytics for beginners_emotions.json\n",
      "Processed text_output/MSc Health Data Science.txt: Emotions saved to emotion_analysis/MSc Health Data Science_emotions.json\n",
      "Processed text_output/Bill Squadron – How big data analytics continues to change pro sports.txt: Emotions saved to emotion_analysis/Bill Squadron – How big data analytics continues to change pro sports_emotions.json\n",
      "Processed text_output/Day in the Life Data Scientist.txt: Emotions saved to emotion_analysis/Day in the Life Data Scientist_emotions.json\n",
      "Processed text_output/What is Data Science - A day in the Life of a Data Scientist by IBM 4.txt: Emotions saved to emotion_analysis/What is Data Science - A day in the Life of a Data Scientist by IBM 4_emotions.json\n",
      ".................................................................\n",
      "*  Emotion analysis process completed in 0.35 second(s)\n",
      ".................................................................\n"
     ]
    }
   ],
   "source": [
    "input_directory  = 'text_output/' \n",
    "output_directory = 'emotion_analysis/'\n",
    "\n",
    "# Extract the emotions of a text\n",
    "run_analyze_emotion(input_directory, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
