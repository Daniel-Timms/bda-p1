in machine learning in one of the most fundamental tasks is when you have a bunch of objects that you want to classify into two categories or more is this picture of a dog or a cat is this dog going up or down svms or support Vector machines are some of the simplest and arguably the most elegant methods for classification each object you want to classify is represented as a point in an end dimensional space and the coordinates of this point are usually called features svms perform the classification test by drawing a hyperplane that is a line in 2D or a plane in 3D in such a way that all points of one category are on one side of the hyperplane and old points of the other category are on the other side and while there could be multiple such hyperplanes svm tries to find the one that best separates the two categories in the sense that it maximizes the distance to points in either category this distance is called the margin and the points that fool exactly on the margin are called the supporting vectors to find this hyperplane in the first place svm requires a training set or a set of points that are already delayed with the correct category this is why is said to be a supervised learning algorithm in the background svm solves a convex of optimization problem that maximizes the smart Jen and where the constraints of each category should be on the correct side of the hyperplane in practice you don't have to worry about the implementation details of this optimization problem using svm can be as simple as load in a python Library preparing your training data feeding into the function and calling predicted to assign the correct category to a new object the biggest pros of svms is that they are easy to understand Implement use and interpret for the more they are effective on the size of the training data is small the Simplicity of his VMS can also be a problem in many applications the points cannot be separated by hyperplane a come work around in this case is to augmented data with your features that are computed from the existing ones be find a separation hyperplane in this higher dimensional space and see project back to the original space a clever technique known as the colonel trick allows us to perform all of these steps in a very efficient manner and now that you know about is you can use them for face detection this was sbm in about 2 minutes like And subscribe if you like the video and see you next time